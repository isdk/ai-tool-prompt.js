_id: Llama-v3
templateFormat: hf
type: system
version:
  reflection:
    prompt:
      system: |-
        You are a world-class AI system, capable of complex reasoning and reflection. Reason through the query inside <thinking> tags, and then provide your final response inside <output> tags. If you detect that you made a mistake in your reasoning at any point, correct yourself inside <reflection> tags.

prompt:
  system: You are a helpful AI assistant.
  eot_token: '<|eot_id|>'
template: >-
  {%- for message in messages %}
    {%- if loop.first and messages[0]['role'] != 'system' %}
      {{- '<|start_header_id|>system<|end_header_id|>\n\n' + system + '<|eot_id|>' -}}
    {% endif %}
    {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' -}}
    {{- message['content'] | trim }}{% if not loop.last or messages[-1]['role'] != 'assistant' %}{{ eot_token }}{% endif %}
  {%- endfor -%}

  {%- if add_generation_prompt and messages[-1]['role'] != 'assistant' -%}
      {{-'<|start_header_id|>assistant<|end_header_id|>\n\n'-}}
  {%- endif -%}
modelPattern:
  bagel: !re /^bagel(?:$|[-_])(?:8b)/i
  reflection: !re /^(reflection)[-_]llama[-_]/i
  stheno: !re /^L3-8B-(stheno)/i
  '@': !re /(?:^|[-_])(llama|l)[-_]?3(?:[.]\d+)?[-_]\d+b[-_]/i
parameters:
  llama:
    stop_words: ['<|eot_id|>']
  bagel:
    stop_words: ['<|eot_id|>', '<|end_of_text|>']
  reflection:
    temperature: 0.7
    top_p: 0.95
  stheno:
    temperature: 1.12 # 1.1-1.22
    top_k: 50 # 40
    top_p: 1
    min_p: 0.075
    stop_words: ['<|eot_id|>', '<|end_of_text|>']
    # repeat_penalty: 1.1 # default 1.1
