_id: Llama-v3
templateFormat: hf
type: system
prompt:
  system: You are a helpful AI assistant.
  eot_token: '<|eot_id|>'
template: >-
  {%- for message in messages %}
    {%- if loop.first and messages[0]['role'] != 'system' %}
      {{- '<|start_header_id|>system<|end_header_id|>\n\n' + system + '<|eot_id|>' -}}
    {% endif %}
    {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' -}}
    {{- message['content'] | trim }}{% if not loop.last or messages[-1]['role'] != 'assistant' %}{{ eot_token }}{% endif %}
  {%- endfor -%}

  {%- if add_generation_prompt and messages[-1]['role'] != 'assistant' -%}
      {{-'<|start_header_id|>assistant<|end_header_id|>\n\n'-}}
  {%- endif -%}
rule:
  - !re /^Meta[-](Llama)[-]3[-]\d+B[-]Instruct$/i
  - !re /^bagel(?:$|[-_])(?:8b)/i
parameters:
  llama:
    stop_words: ['<|eot_id|>']
