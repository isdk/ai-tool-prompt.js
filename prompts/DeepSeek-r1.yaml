_id: DeepSeekR1
templateFormat: hf
type: system
prompt:
  bos_token: '<｜begin▁of▁sentence｜>'
  eos_token: "<｜end▁of▁sentence｜>"
supports:
  - 'tools'
  - thinkMode: ['deep']
shouldThink:
  mode: 'deep'
  thinkTag: ["<think>", "</think>"]
# For mathematical problems, it is advisable to include a directive in your prompt such as:
# "Please reason step by step, and put your final answer within \boxed{}."
template: >-
  {% set ns = namespace(is_tool=false, is_output_first=true) %}
  {%- for message in messages %}
    {%- if message['role'] == 'user' or message['role'] == 'system' -%}
      {%- set ns.is_tool = false -%}
      {{- '<｜User｜>' + message['content'] -}}
    {%- elif message['role'] == 'assistant' -%}
      {%- set ns.is_tool = false -%}
      {%- set has_content = false -%}
      {%- if message['tool_calls'] and message['tool_calls']|length > 0 %}
        {%- set has_content = true -%}
        {{'<｜Assistant｜><｜tool▁calls▁begin｜>'}}
        {%- for tool in message['tool_calls'] %}
          {%- set tool_call = '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<｜tool▁call▁end｜>' -%}
          {%- if loop.first %}
            {{- tool_call}}
          {%- else %}
            {{- '\n' + tool_call}}
          {%- endif %}
        {%- endfor %}
        {{-'<｜tool▁calls▁end｜>'}}
      {%- endif -%}
      {%- if message['content'] %}
        {%- set has_content = true -%}
        {%- set content = message['content'] -%}
        {%- if ns.is_tool %}
          {{'<｜tool▁outputs▁end｜>' + content}}
          {%- set ns.is_tool = false -%}
        {%- else %}
          {% if '</think>' in content %}
            {% set content = (content.split('</think>'))[-1] %}
          {% endif %}
          {{- '<｜Assistant｜>' + content -}}
        {%- endif -%}
      {%- endif -%}
      {%- if has_content and not loop.last %}{{ eos_token }}{% endif %}
    {%- elif message['role'] == 'tool' -%}
      {%- set ns.is_tool = true -%}
      {%- if ns.is_output_first %}
        {{-'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}
        {%- set ns.is_output_first = false %}
      {%- else %}
        {{'\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}
      {%- endif %}
    {%- endif -%}
  {%- endfor -%}
  {%- if ns.is_tool %}
    {{-'<｜tool▁outputs▁end｜>'}}
  {%- endif %}
  {%- if add_generation_prompt and messages[-1]['role'] != 'assistant' -%}
      {{-'<｜Assistant｜>'-}}
  {%- endif -%}
modelPattern:
  'Sky-T1-mini': !re /^(sky-t1-mini)(?:[-_]|$)/i
  '@': !re /^(deepseek-r1|deepseekr1|deepsex)(?:[-_]|$)/i
priority: 10
parameters:
  # 最大生成长度锁定在 32768 个 token，温度值维持在 0.6，top-p 值定格在 0.95。每个测试都生成 64 个响应样本。
  '@':
    temperature: 0.6 # 0.5-0.7
    top_p: 0.95

